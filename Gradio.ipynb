{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Major_project\\code\\deep\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as timer\n",
    "from torch.utils.data import Subset\n",
    "import cv2, glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease vs Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class Bin_EnsembleModel(nn.Module):\n",
    "    def __init__(self,model1,model2, model3):\n",
    "        super(Bin_EnsembleModel, self).__init__()\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.model3 = model3\n",
    "     \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        preds1 = torch.sigmoid(self.model1(x))\n",
    "        preds2 = torch.sigmoid(self.model2(x))\n",
    "        preds3 = torch.sigmoid(self.model3(x))\n",
    " \n",
    "        preds = ( preds1 + preds2 + preds3) / 3\n",
    "        return preds # return the predictions on the same device as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Binaryduper_EnsembleModel(nn.Module):\n",
    "    def __init__(self, model1, model2, model3,model4):\n",
    "        super(Binaryduper_EnsembleModel, self).__init__()\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.model3 = model3\n",
    "        self.model4 = model4\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        preds1 = torch.sigmoid(self.model1(x))\n",
    "        preds2 = torch.sigmoid(self.model2(x))\n",
    "        preds3 = torch.sigmoid(self.model3(x))\n",
    "        preds4 = torch.sigmoid(self.model4(x))\n",
    "        preds = (preds1 + preds2 + preds3 + preds4) / 4\n",
    "        return preds # return the predictions on the same device as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Major_project\\code\\deep\\lib\\site-packages\\gradio\\inputs.py:257: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "E:\\Major_project\\code\\deep\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "E:\\Major_project\\code\\deep\\lib\\site-packages\\gradio\\outputs.py:197: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n",
      "E:\\Major_project\\code\\deep\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  warnings.warn(value)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "\n",
    "model1 = torch.load('E:/Major_project/code/models/Ensemble_Models/Binary_duper4_ensemble_model_02_05.pt',map_location=torch.device('cpu'))\n",
    "class_names1= ['Disease', 'Normal']\n",
    "title = \"Disease Vs Normal\"\n",
    "description = '''This model classifies the given fundus image into Diseased or Normal '''\n",
    "input_img = gr.inputs.Image(type='pil', label='Input image')\n",
    "\n",
    "def preprocess1(image):\n",
    "    image = image.resize((224,224))\n",
    "    tensor = transforms.ToTensor()(image)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    return tensor\n",
    "\n",
    "def predict1(image):\n",
    "    tensor = preprocess1(image)\n",
    "    outputs = model1(tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    return class_names1[predicted.item()]\n",
    "\n",
    "interface1 = gr.Interface(\n",
    "    fn=predict1,\n",
    "    inputs= input_img,\n",
    "    outputs=gr.outputs.Label(num_top_classes=2, label='Predicted label'),\n",
    "    allow_flagging='never',\n",
    "    title=title,\n",
    "    description=description\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Diseases Vs Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "class Superduper_EnsembleModel(nn.Module):\n",
    "    def __init__(self, model1, model2, model3,model4):\n",
    "        super(Superduper_EnsembleModel, self).__init__()\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.model3 = model3\n",
    "        self.model4 = model4\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        preds1 = torch.sigmoid(self.model1(x))\n",
    "        preds2 = torch.sigmoid(self.model2(x))\n",
    "        preds3 = torch.sigmoid(self.model3(x))\n",
    "        preds4 = torch.sigmoid(self.model4(x))\n",
    "        preds = (preds1 + preds2 + preds3 + preds4) * 4\n",
    "        return preds # return the predictions on the same device as input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "\n",
    "model2 = torch.load('E:/Major_project/code/models/Ensemble_Models/Super_duper4_ensemble_model.pt',map_location=torch.device('cpu'))\n",
    "# labels= ['Disease', 'Normal']\n",
    "labels = ['Age_Macular_Degeneration','Cataract','Diabetic_Retinopathy','Glaucoma','Myopia','Healthy Fundus']\n",
    "\n",
    "\n",
    "def preprocess2(image):\n",
    "    image = image.resize((224,224))\n",
    "    tensor = transforms.ToTensor()(image)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    return tensor\n",
    "title = \"Ocular Disease Recognition\"\n",
    "description = '''This model classifies the given fundus image in different diseases.. '''\n",
    "\n",
    "def predict2(image):\n",
    "  image = preprocess2(image)\n",
    "  with torch.no_grad():\n",
    "    prediction = torch.nn.functional.softmax(model2(image)[0], dim=0)\n",
    "    confidences = {labels[i]: float(prediction[i]) for i in range(6)}    \n",
    "  return confidences\n",
    "\n",
    "interface2 = gr.Interface(\n",
    "    fn=predict2,\n",
    "    inputs=gr.inputs.Image(type='pil', label='Input image'),\n",
    "    outputs=gr.outputs.Label(num_top_classes=4, label='Predicted label'),\n",
    "    title = title,\n",
    "    description = description,\n",
    "    allow_flagging='never'\n",
    ")\n",
    "\n",
    "# interface2.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes RetinoPathy Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, model2, model3, model4):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self.model2 = model2\n",
    "        self.model3 = model3\n",
    "        self.model4 = model4\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        preds2 = torch.sigmoid(self.model2(x))\n",
    "        preds3 = torch.sigmoid(self.model3(x))\n",
    "        preds4 = torch.sigmoid(self.model4(x))\n",
    "\n",
    "        preds = (preds2 + preds3 + preds4 ) * 27\n",
    "        return preds # return the predictions on the same device as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "model3 = torch.load('E:/Major_project/code/models/Ensemble_Models/dr_ensemble.pt',map_location=torch.device('cpu'))\n",
    "labels3 = ['Normal','Stage 1','Stage 2','Stage 3','Stage 4']\n",
    "\n",
    "\n",
    "def preprocess3(image):\n",
    "    image = np.asarray(image)\n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l_channel, a_channel, b_channel = cv2.split(image_lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l_channel)\n",
    "    merged_channels = cv2.merge((cl, a_channel, b_channel))\n",
    "    final_image = cv2.cvtColor(merged_channels, cv2.COLOR_LAB2BGR)\n",
    "    final_image = Image.fromarray(final_image)\n",
    "    image = final_image.resize((224,224))\n",
    "    img = transforms.Grayscale(num_output_channels=3)(image)\n",
    "    tensor = transforms.ToTensor()(img)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    return tensor\n",
    "\n",
    "title = \"Diabetic Retinopathy Stage Classification\"\n",
    "# description = '''This model classifies the given fundus image in different diseases.. '''\n",
    "\n",
    "def predict3(image):\n",
    "  image = preprocess3(image)\n",
    "  with torch.no_grad():\n",
    "    prediction = torch.nn.functional.softmax(model3(image)[0], dim=0)\n",
    "    confidences = {labels3[i]: float(prediction[i]) for i in range(5)}    \n",
    "  return confidences\n",
    "\n",
    "interface3 = gr.Interface(\n",
    "    fn=predict3,\n",
    "    inputs=gr.inputs.Image(type='pil', label='Input image'),\n",
    "    outputs=gr.outputs.Label(num_top_classes=5, label='Predicted label'),\n",
    "    allow_flagging='never',\n",
    "    title=title\n",
    "#     description=description\n",
    ")\n",
    "\n",
    "# interface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Major_project\\code\\deep\\lib\\site-packages\\gradio\\blocks.py:863: UserWarning: api_name predict already exists, using predict_1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = \"Ocular Disease Recognition\"\n",
    "description = '''This model classifies the given fundus image in different diseases.. '''\n",
    "\n",
    "interface0 = gr.Parallel(interface1,interface2)\n",
    "interface = gr.TabbedInterface([interface0, interface3], [\"Ocular Diseases\", \"Diabetic Retinopathy\"], title='Ocular Disease Recognition with Ensemble Techniques')\n",
    "# interface = gr.TabbedInterface([interface1,interface2, interface3], , title='Ocular Disease Recognition with Ensemble Techniques')\n",
    "\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.27.0\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "print(gr.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
