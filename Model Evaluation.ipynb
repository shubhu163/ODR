{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Major_project\\code\n"
     ]
    }
   ],
   "source": [
    "cd code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as timer\n",
    "from torch.utils.data import Subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Major_project\\\\code'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, model1, model2, model3):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.model3 = model3\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        preds1 = torch.sigmoid(self.model1(x))\n",
    "        preds2 = torch.sigmoid(self.model2(x))\n",
    "        preds3 = torch.sigmoid(self.model3(x))\n",
    "        preds = (preds1 + preds2 + preds3) / 3\n",
    "        return preds # return the predictions on the same device as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Major_project\\\\code'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[215  73]\n",
      " [ 34 254]]\n",
      "Accuracy: 0.8142361111111112\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# # Define the transform for the test data\n",
    "\n",
    "# # Load the test dataset\n",
    "# test_dir = 'path/to/test/data'\n",
    "# test_dataset = datasets.ImageFolder(test_dir, transform=data_transform1)\n",
    "data_transform = transforms.Compose([\n",
    "    # Resize our images to 64x64\n",
    "    transforms.Resize(size=(320, 320)),\n",
    "    # Flip the images randomly on the horizontal \n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(20),\n",
    "    #transforms.RandomInvert(0.4),\n",
    "    # Turn the image into a torch.Tensor\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "val_dir= 'Disease_vs_Normal/test'\n",
    "test_dataset = datasets.ImageFolder(val_dir, transform=data_transform)\n",
    "\n",
    "model = torch.load('models/Disease/ensemble_model (1).pt', map_location=torch.device('cpu'))\n",
    "\n",
    "# Load the pretrained ResNet18 model\n",
    "# model = torch.load(\"models/Disease_vs_Normal/Multiple_model1_25_04_2023.Resnet_V2_8-Batch_70.pt\" , map_location=torch.device('cpu'))\n",
    "\n",
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the device\n",
    "model.to(device)\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataset:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = torch.tensor(labels).to(device)\n",
    "        outputs = model(inputs.unsqueeze(0)).to(device)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        true_labels.extend((labels.item(),))\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Compute the accuracy\n",
    "accuracy = (cm.diagonal().sum() / cm.sum())\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "\n",
    "# model = torch.load('E:/Major_project/code/models/Disease_Vs _Normal/super_model_disease_vs_normal.pt',map_location=torch.device('cpu'))\n",
    "class_names= ['Disease', 'Normal']\n",
    "\n",
    "\n",
    "def preprocess(image):\n",
    "    image = image.resize((224,224))\n",
    "    tensor = transforms.ToTensor()(image)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    return tensor\n",
    "\n",
    "def predict(image):\n",
    "    tensor = preprocess(image)\n",
    "    outputs = model(tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    return class_names[predicted.item()]\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.inputs.Image(type='pil', label='Input image'),\n",
    "    outputs=gr.outputs.Label(num_top_classes=2, label='Predicted label')\n",
    ")\n",
    "\n",
    "interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
